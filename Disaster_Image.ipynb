{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **IMAGE** **INPAINTING**"
      ],
      "metadata": {
        "id": "VbV9ThAWYJWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "4q_ans_n8RTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "3VZLWz1H8W-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils as vutils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# Set the device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "7_wcJTck-Gpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = '/content/gdrive/MyDrive/Dataset/train/images'\n",
        "root_dirm = '/content/gdrive/MyDrive/Dataset/train/masked'"
      ],
      "metadata": {
        "id": "zkmNF6vaZNIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root_dir,transform=None):\n",
        "        self.root_dir= root_dir\n",
        "        self.transform = transform\n",
        "        self.image_folder = ImageFolder(root_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_folder)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path, _ = self.image_folder.imgs[index]\n",
        "\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img"
      ],
      "metadata": {
        "id": "2xvjfPYIZNo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PairedImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root_dir,root_dirm,transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.root_dirm = root_dirm\n",
        "        self.transform = transform\n",
        "        self.image_folder = ImageFolder(root_dir)\n",
        "        self.mask_folder = ImageFolder(root_dirm)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_folder)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path, _ = self.image_folder.imgs[index]\n",
        "        mask_path,_= self.mask_folder.imgs[index]\n",
        "\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        masked_img = Image.open(mask_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "            masked_img = self.transform(masked_img)\n",
        "\n",
        "        mask = torch.all(masked_img == 0, dim=0)\n",
        "\n",
        "        # Create a new 3D tensor with three channels\n",
        "        result_img = torch.zeros_like(masked_img)\n",
        "\n",
        "        # Set white pixels in all channels to 1\n",
        "        for channel in range(masked_img.shape[0]):\n",
        "            result_img[channel, mask] = 1\n",
        "\n",
        "        return img, masked_img,mask"
      ],
      "metadata": {
        "id": "l-zuVyPvt3kG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Create the paired dataset\n",
        "paired_dataset = PairedImageDataset(root_dir,root_dirm, transform=transform)\n",
        "\n",
        "# Create a DataLoader for batching\n",
        "batch_size = 32\n",
        "traingen = DataLoader(paired_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Create a validation dataset\n",
        "root_dirv = '/content/gdrive/MyDrive/Dataset/validation/images'\n",
        "root_dirvm = '/content/gdrive/MyDrive/Dataset/validation/masked'\n",
        "\n",
        "paired_valdata = PairedImageDataset(root_dirv,root_dirvm, transform=transform)\n",
        "testgen = DataLoader(paired_valdata, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "3Jb44KjLZh6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, batch in enumerate(traingen):\n",
        "    if i >= 1:  # Display only the first batch\n",
        "        break\n",
        "\n",
        "    images, masked_images,mask = batch\n",
        "    images = images.to(device)\n",
        "    masked_images = masked_images.to(device)\n",
        "    mask = mask.to(device)\n",
        "    # Create a grid of images and their masked counterparts\n",
        "    combined_images = torch.cat([images, masked_images,mask], dim=3)\n",
        "\n",
        "    # Display the grid using matplotlib\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Batch {i + 1}: Images and Masked Images\")\n",
        "    plt.imshow(np.transpose(vutils.make_grid(combined_images, padding=2, normalize=True).cpu(), (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "a3YEtu6vXkKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self,img_size,latent_dim,channels):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.init_size = img_size // 4\n",
        "        self.linear_layer = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.linear_layer(z)\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
        "        image = self.conv_layers(out)\n",
        "        return image\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,channels,img_size):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, bn=True):\n",
        "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
        "            if bn:\n",
        "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
        "            return block\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            *discriminator_block(channels, 16, bn=False),\n",
        "            *discriminator_block(16, 32),\n",
        "            *discriminator_block(32, 64),\n",
        "            *discriminator_block(64, 128),\n",
        "        )\n",
        "\n",
        "        self.ds_size = img_size // 2 ** 4\n",
        "        self.adverse_layer = nn.Sequential(nn.Linear(128 * self.ds_size ** 2, 1), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, image):\n",
        "        out = self.conv_layers(image)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        validity = self.adverse_layer(out)\n",
        "        return validity"
      ],
      "metadata": {
        "id": "EpgxwL3OaHSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0.0)"
      ],
      "metadata": {
        "id": "sspQP0S5HB29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "batch_size=64\n",
        "latent_dim=100\n",
        "channels = 3\n",
        "img_size = 256\n",
        "prior_weight = 0.003\n",
        "optim_steps = 1500"
      ],
      "metadata": {
        "id": "617ilQh-aWeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def context_loss(masked_images, generated_images, masks, weighted=True):\n",
        "    return torch.sum(((masked_images-generated_images)**2)*masks)"
      ],
      "metadata": {
        "id": "AjliRA57akt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will initially train GAN on our masked images\n",
        "print(\"Starting training ...\")\n",
        "epoch = 0\n",
        "dataset = ImageDataset(root_dirm,transform=transform) #generate masked images to train the generator on\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "generator = Generator(img_size,latent_dim,channels).cuda()\n",
        "discriminator =Discriminator(channels,img_size).cuda()\n",
        "generator.apply(weights_init_normal)\n",
        "discriminator.apply(weights_init_normal)\n",
        "adversarial_loss = nn.BCELoss()\n",
        "optimizer_G = optim.Adam(generator.parameters())\n",
        "optimizer_D = optim.Adam(discriminator.parameters())\n",
        "\n",
        "\n",
        "\n",
        "while epoch < epochs:\n",
        "    epoch = epoch+1\n",
        "    total_G_loss = 0.0\n",
        "    total_D_loss = 0.0\n",
        "\n",
        "    for i, masked_images in enumerate(dataloader):\n",
        "        valid = torch.FloatTensor(masked_images.shape[0], 1).fill_(1.0).cuda()\n",
        "        fake = torch.FloatTensor(masked_images.shape[0], 1).fill_(0.0).cuda()\n",
        "        masked_images = masked_images.cuda()\n",
        "\n",
        "        #  Train Generator\n",
        "        optimizer_G.zero_grad()\n",
        "        z = torch.FloatTensor(np.random.normal(0, 1, (masked_images.shape[0], latent_dim))).cuda()\n",
        "        gen_imgs = generator(z)\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "        total_G_loss += g_loss.cpu().detach().numpy()\n",
        "\n",
        "        #  Train Discriminator\n",
        "        optimizer_D.zero_grad()\n",
        "        discriminator_opinion_real = discriminator(masked_images)\n",
        "        discriminator_opinion_fake = discriminator(gen_imgs.detach())\n",
        "        real_loss = adversarial_loss(discriminator_opinion_real, valid)\n",
        "        fake_loss = adversarial_loss(discriminator_opinion_fake, fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "        total_D_loss += d_loss.cpu().detach().numpy()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{epoch}] | D loss: {d_loss:.4f} | G loss: {g_loss:.4f}')\n",
        "\n",
        "\n",
        "    print(\n",
        "        \"[Epoch {}/{}] \\t[D loss: {:.3f}] \\t[G loss: {:.3f}]\".format(\n",
        "            epoch,epochs, total_D_loss, total_G_loss)\n",
        "    )\n",
        "\n",
        "    torch.save({\"epoch\": epoch,\n",
        "                \"state_dict_G\": generator.state_dict(),\n",
        "                \"state_dict_D\": discriminator.state_dict(),\n",
        "                \"optimizer_G\": optimizer_G.state_dict(),\n",
        "                \"optimizer_D\": optimizer_D.state_dict()\n",
        "                }, '/content/gdrive/MyDrive/gan.pth')"
      ],
      "metadata": {
        "id": "BSfaNM2wgkGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample images displayed\n",
        "\n",
        "latent_dim = 100\n",
        "from torchvision.utils import make_grid\n",
        "# Load the model and optimizer state_dict\n",
        "checkpoint = torch.load('/content/gdrive/MyDrive/gan.pth')\n",
        "generator = Generator(img_size,latent_dim,channels)\n",
        "generator.load_state_dict(checkpoint['state_dict_G'])\n",
        "\n",
        "# Set the generator to evaluation mode\n",
        "generator.eval()\n",
        "\n",
        "# Generate new images\n",
        "num_images_to_generate = 20\n",
        "z_optimum = torch.FloatTensor(np.random.normal(0, 1, (num_images_to_generate, latent_dim)))\n",
        "generated_images = generator(z_optimum)\n",
        "\n",
        "# Convert the generated images to a grid for visualization\n",
        "generated_images_grid = make_grid(generated_images.cpu().detach(), nrow=5, normalize=True)\n",
        "\n",
        "# Convert the PyTorch tensor to a NumPy array and transpose the dimensions\n",
        "image_numpy = generated_images_grid.numpy().transpose(1, 2, 0)\n",
        "\n",
        "# Display the generated image\n",
        "plt.imshow(image_numpy)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CPmJtYRzJ54o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to alculate optimum latent dimension - not working\n",
        "\n",
        "from torchvision.utils import save_image\n",
        "# Using trained GAN model\n",
        "for i,(original_images,corrupted_images,masks) in enumerate(dataset):\n",
        "    corrupted_images, masks= corrupted_images, masks\n",
        "    z_optimum = nn.Parameter(torch.FloatTensor(np.random.normal(0, 1, (corrupted_images.shape[0],latent_dim,))))\n",
        "    optimizer_inpaint = optim.Adam([z_optimum])\n",
        "\n",
        "    print(\"Starting backprop to input ...\")\n",
        "    for epoch in range(optim_steps):\n",
        "        optimizer_inpaint.zero_grad()\n",
        "        generated_images = generator(z_optimum)\n",
        "        discriminator_opinion = discriminator(generated_images)\n",
        "        c_loss = context_loss(corrupted_images, generated_images,masks) # calculate loss only for masked region\n",
        "        prior_loss = torch.sum(-torch.log(discriminator_opinion))\n",
        "        inpaint_loss = c_loss +prior_weight*prior_loss\n",
        "        inpaint_loss.backward()\n",
        "        optimizer_inpaint.step()\n",
        "        print(\"[Epoch: {}/{}] \\t[Loss: \\t[Context: {:.3f}] \\t[Prior: {:.3f}] \\t[Inpaint: {:.3f}]]  \\r\".format(1+epoch,optim_steps, c_loss,\n",
        "                                                                            prior_loss, inpaint_loss),end=\"\")\n",
        "    print(\"\")\n",
        "\n",
        "        for idx in range(generated_images.shape[0]):\n",
        "        # Get the parent path of the original image\n",
        "          original_image_path = traingen.dataset.img_paths[i * traingen.batch_size + idx]\n",
        "          parent_path = os.path.dirname(original_image_path)\n",
        "\n",
        "          # Create a directory for each category if it doesn't exist\n",
        "          category_dir = os.path.join(os.path.basename(parent_path),'generated')\n",
        "          os.makedirs(category_dir, exist_ok=True)\n",
        "\n",
        "          # Save the final_img\n",
        "          save_image(generated_img, os.path.join(category_dir, f'final_img_{i}_{idx}.png'))"
      ],
      "metadata": {
        "id": "BISbLKFxjQ1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from torchvision.transforms import ToPILImage\n",
        "# Functions for blending operations\n",
        "\n",
        "def mix_pixel(pix_1, pix_2, perc):\n",
        "    return (perc / 255 * pix_1) + ((255 - perc) / 255 * pix_2)\n",
        "\n",
        "def blend_images(img_orig, img_for_overlay, img_mask):\n",
        "    if len(img_mask.shape) != 3:\n",
        "        img_mask = cv2.cvtColor(img_mask, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    img_res = mix_pixel(img_orig, img_for_overlay, img_mask)\n",
        "    return img_res.astype(np.uint8)\n",
        "\n",
        "def blend_images_using_mask(img, img_insert, result_img):\n",
        "    to_pil = ToPILImage()\n",
        "\n",
        "    img_pil = to_pil(img)\n",
        "    img_insert_pil = to_pil(img_insert)\n",
        "    img_insert_mask_pil = to_pil(result_img)\n",
        "\n",
        "    # Convert PIL Images to NumPy arrays (OpenCV format)\n",
        "    img_array = np.array(img_pil)\n",
        "    img_insert_array = np.array(img_insert_pil)\n",
        "    img_insert_mask_array = np.array(img_insert_mask_pil)\n",
        "\n",
        "    # Blend images using the provided functions\n",
        "    img_blended_array = blend_images(img_array, img_insert_array, img_insert_mask_array)\n",
        "\n",
        "    # Resize images for display (if needed)\n",
        "    rf = 0.4\n",
        "    img_array_resized = cv2.resize(img_array, (int(img_array.shape[1] * rf), int(img_array.shape[0] * rf)), interpolation=cv2.INTER_CUBIC)\n",
        "    img_insert_array_resized = cv2.resize(img_insert_array, (int(img_insert_array.shape[1] * rf), int(img_insert_array.shape[0] * rf)), interpolation=cv2.INTER_CUBIC)\n",
        "    img_blended_array_resized = cv2.resize(img_blended_array, (int(img_blended_array.shape[1] * rf), int(img_blended_array.shape[0] * rf)), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    return img_blended_array_resized"
      ],
      "metadata": {
        "id": "SxiUjKeVjSy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('/content/gdrive/MyDrive/gan.pth', map_location=torch.device('cpu'))\n",
        "generator = Generator(img_size,latent_dim,channels)\n",
        "generator.load_state_dict(checkpoint['state_dict_G'])\n",
        "\n",
        "# Set the generator to evaluation mode\n",
        "generator.eval()\n",
        "generator = generator.to('cpu')\n",
        "z_optimum = nn.Parameter(torch.FloatTensor(np.random.normal(0, 1, (1,latent_dim,))))\n",
        "\n",
        "for i,(original_images,corrupted_images,masks) in enumerate(traingen):\n",
        "    z_optimum = nn.Parameter(torch.FloatTensor(np.random.normal(0, 1, (corrupted_images.shape[0],latent_dim,))))\n",
        "    generated_images = generator(z_optimum)\n",
        "    for idx in range(generated_images.shape[0]):\n",
        "      final_img = blend_images_using_mask(generated_images[idx],original_images[idx],masks[idx])\n",
        "    # Get the parent path of the original image\n",
        "      original_image_path = traingen.dataset.img_paths[i * traingen.batch_size + idx]\n",
        "      parent_path = os.path.dirname(original_image_path)\n",
        "\n",
        "      # Create a directory for each category if it doesn't exist\n",
        "      category_dir = os.path.join(os.path.basename(parent_path),'generated')\n",
        "      os.makedirs(category_dir, exist_ok=True)\n",
        "\n",
        "      # Save the final_img\n",
        "      save_image(final_img, os.path.join(category_dir, f'final_img_{i}_{idx}.png'))\n",
        "\n"
      ],
      "metadata": {
        "id": "7zpTYLPJjaUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CLASSIFICATION**"
      ],
      "metadata": {
        "id": "MVg3_pDFNyfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.svm import SVC\n"
      ],
      "metadata": {
        "id": "hwx63SMhN1TT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/gdrive/MyDrive/Dataset/train/images'\n",
        "test_dir = '/content/gdrive/MyDrive/Dataset/validation/images'"
      ],
      "metadata": {
        "id": "IuQcPjhoY1nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalizing the dataset and pre-processing the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Load the dataset using ImageFolder and apply the transforms\n",
        "train_dataset = ImageFolder(root=train_dir, transform=transform)\n",
        "val_dataset = ImageFolder(root=test_dir, transform=transform)\n",
        "\n",
        "\n",
        "# Define the data loaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Get the number of classes\n",
        "num_classes = len(train_dataset.classes)\n",
        "\n",
        "# Get the class index\n",
        "class_index = 0  # Replace with the desired class index\n",
        "\n",
        "# Get the class name corresponding to the class index\n",
        "for class_index in range (num_classes):\n",
        " class_name = train_dataset.classes[class_index]\n",
        " print(class_name)"
      ],
      "metadata": {
        "id": "SCNPNeuXYTOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading pre-trained model and only last two layers weights wil be updated\n",
        "\n",
        "AlexNet_model = models.alexnet(pretrained=True)\n",
        "AlexNet_model.classifier[4] = nn.Linear(4096,1024)\n",
        "AlexNet_model.classifier[6] = nn.Linear(1024,num_classes)\n",
        "AlexNet_model.classifier[4].requires_grad_(True)\n",
        "AlexNet_model.classifier[6].requires_grad_(True)\n",
        "\n",
        "AlexNet_model.eval()"
      ],
      "metadata": {
        "id": "cRt-qS-7ZWGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "\n",
        "# training\n",
        "def train(model, trainloader, optimizer, criterion, device):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    print('Training')\n",
        "    train_running_loss = 0.0\n",
        "    train_running_correct = 0\n",
        "    counter = 0\n",
        "    for i, data in tqdm(enumerate(trainloader), total=len(trainloader)):\n",
        "        counter += 1\n",
        "        image, labels = data\n",
        "        image, labels = image.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(image)\n",
        "        # calculate the loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        train_running_loss += loss.item()\n",
        "        # calculate the accuracy\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        train_running_correct += (preds == labels).sum().item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # loss and accuracy for the complete epoch\n",
        "    epoch_loss = train_running_loss / counter\n",
        "    epoch_acc = 100. * (train_running_correct / len(trainloader.dataset))\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# validation\n",
        "def validate(model, testloader, criterion, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print('Validation')\n",
        "    valid_running_loss = 0.0\n",
        "    valid_running_correct = 0\n",
        "    counter = 0\n",
        "    with torch.no_grad():\n",
        "        for i, data in tqdm(enumerate(testloader), total=len(testloader)):\n",
        "            counter += 1\n",
        "\n",
        "            image, labels = data\n",
        "            image, labels = image.to(device), labels.to(device)  # move data to GPU\n",
        "            outputs = model(image)\n",
        "            # calculate the loss\n",
        "            loss = criterion(outputs, labels)\n",
        "            valid_running_loss += loss.item()\n",
        "            # calculate the accuracy\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            valid_running_correct += (preds == labels).sum().item()\n",
        "\n",
        "    # loss and accuracy for the complete epoch\n",
        "    epoch_loss = valid_running_loss / counter\n",
        "    epoch_acc = 100. * (valid_running_correct / len(testloader.dataset))\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "2T0whLscaFHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from utils import save_model, save_plots\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(AlexNet_model.parameters(num_classes), lr=0.001, momentum=0.9)\n",
        "epochs = 20\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_loss, valid_loss = [], []\n",
        "train_acc, valid_acc = [], []\n",
        "# start the training\n",
        "for epoch in range(epochs):\n",
        "    print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n",
        "    train_epoch_loss, train_epoch_acc = train(AlexNet_model, train_loader,\n",
        "                                              optimizer, criterion,device)\n",
        "    valid_epoch_loss, valid_epoch_acc = validate(AlexNet_model, val_loader,\n",
        "                                                 criterion,device)\n",
        "    train_loss.append(train_epoch_loss)\n",
        "    valid_loss.append(valid_epoch_loss)\n",
        "    train_acc.append(train_epoch_acc)\n",
        "    valid_acc.append(valid_epoch_acc)\n",
        "    print(f\"Training loss: {train_epoch_loss:.3f}, training acc: {train_epoch_acc:.3f}\")\n",
        "    print(f\"Validation loss: {valid_epoch_loss:.3f}, validation acc: {valid_epoch_acc:.3f}\")\n",
        "    print('-'*50)\n",
        "\n",
        "print('TRAINING COMPLETE')"
      ],
      "metadata": {
        "id": "MqNuWkCwCCEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_curves(train_loss, valid_loss, train_acc, valid_acc):\n",
        "    # Plot Loss Curve\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_loss, label='Training Loss', color='blue')\n",
        "    plt.plot(valid_loss, label='Validation Loss', color='red')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Accuracy Curve\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_acc, label='Training Accuracy', color='blue')\n",
        "    plt.plot(valid_acc, label='Validation Accuracy', color='red')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_curves(train_loss, valid_loss, train_acc, valid_acc)\n"
      ],
      "metadata": {
        "id": "D4LeidE1EEkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(AlexNet_model.state_dict(), '/content/gdrive/MyDrive/model_classification.pth')"
      ],
      "metadata": {
        "id": "jwCUCOr7hrqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.alexnet(pretrained=False)\n",
        "model.classifier[4] = nn.Linear(4096,1024)\n",
        "model.classifier[6] = nn.Linear(1024,num_classes)\n",
        "model.load_state_dict(torch.load('/content/gdrive/MyDrive/model_classification.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "7Z1aRnIQ-kQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removing last linear layer\n",
        "model.classifier = nn.Sequential(*[model.classifier[i] for i in range(5)])\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "G0F6Ug1X1PB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to extract features from a batch of images\n",
        "def extract_features(model, dataloader):\n",
        "    model.eval()\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            features = model(inputs)\n",
        "            all_features.append(features.squeeze().numpy())\n",
        "            all_labels.append(labels.numpy())\n",
        "\n",
        "    all_features = np.vstack(all_features)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "\n",
        "    return all_features, all_labels\n",
        "\n",
        "X_train_features, y_train = extract_features(model, train_loader)\n",
        "X_test_features, y_test = extract_features(model, val_loader)\n",
        "\n",
        "print(\"X_train_features shape:\", X_train_features.shape)\n",
        "print(\"X_test_features shape:\", X_test_features.shape)"
      ],
      "metadata": {
        "id": "UfmfcjXL1vD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_confusion_matrix(y_test, y_pred):\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "7CSRHvRI-nJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train an SVM classifier\n",
        "svm_classifier = SVC(kernel='linear',C=1.0, random_state=42, verbose=False)\n",
        "svm_classifier.fit(X_train_features, y_train)\n",
        "\n",
        "# Make predictions on the training set\n",
        "y_train_pred = svm_classifier.predict(X_train_features)\n",
        "\n",
        "# Compute training accuracy\n",
        "training_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "print(\"Training Accuracy:\", training_accuracy*100)\n",
        "\n",
        "y_pred = svm_classifier.predict(X_test_features)\n",
        "# Compute test accuracy\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy:\", test_accuracy*100)\n",
        "\n",
        "plot_confusion_matrix(y_test,y_pred)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "-jHTlRy-7EtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ycL3QNos7E7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pIn161qdQh6j"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}